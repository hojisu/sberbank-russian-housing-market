{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proprocessing & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.display.max_columns = 300\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Feature/Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./data/train.csv', parse_dates=['timestamp'])\n",
    "df_test = pd.read_csv('./data/test.csv', parse_dates=['timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## outlier & clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## clean data\n",
    "# check life_sq > full_sq -> change np.NaN\n",
    "bad_index = df_train[df_train.life_sq > df_train.full_sq].index\n",
    "df_train.loc[bad_index, \"life_sq\"] = np.NaN\n",
    "bad_index = df_test[df_test.life_sq > df_test.full_sq].index\n",
    "df_test.loc[bad_index, \"life_sq\"] = np.NaN\n",
    "bad_index = df_train[df_train.life_sq < 5].index\n",
    "df_train.loc[bad_index, \"life_sq\"] = np.NaN\n",
    "bad_index = df_test[df_test.life_sq < 5].index\n",
    "df_test.loc[bad_index, \"life_sq\"] = np.NaN\n",
    "bad_index = df_train[df_train.full_sq < 5].index\n",
    "df_train.loc[bad_index, \"full_sq\"] = np.NaN\n",
    "bad_index = df_test[df_test.full_sq < 5].index\n",
    "df_test.loc[bad_index, \"full_sq\"] = np.NaN\n",
    "bad_index = df_train[df_train.kitch_sq >= df_train.life_sq].index\n",
    "df_train.loc[bad_index, \"kitch_sq\"] = np.NaN\n",
    "bad_index = df_test[df_test.kitch_sq >= df_test.life_sq].index\n",
    "df_test.loc[bad_index, \"kitch_sq\"] = np.NaN\n",
    "bad_index = df_train[(df_train.kitch_sq == 0).values + (df_train.kitch_sq == 1).values].index\n",
    "df_train.loc[bad_index, \"kitch_sq\"] = np.NaN\n",
    "bad_index = df_test[(df_test.kitch_sq == 0).values + (df_test.kitch_sq == 1).values].index\n",
    "df_test.loc[bad_index, \"kitch_sq\"] = np.NaN\n",
    "bad_index = df_train[(df_train.full_sq > 210) & (df_train.life_sq / df_train.full_sq < 0.3)].index\n",
    "df_train.loc[bad_index, \"full_sq\"] = np.NaN\n",
    "bad_index = df_test[(df_test.full_sq > 200) & (df_test.life_sq / df_test.full_sq < 0.3)].index\n",
    "df_test.loc[bad_index, \"full_sq\"] = np.NaN\n",
    "df_train.loc[[13117], \"build_year\"] = df_train.loc[[13117], \"kitch_sq\"]\n",
    "\n",
    "## outlier\n",
    "# brings error down a lot by removing extreme price per sqm\n",
    "df_train.loc[df_train.state == 33, 'state'] = 3\n",
    "df_train.loc[df_train['life_sq'] > 1000, 'life_sq'] = np.median(df_train['life_sq'].dropna())\n",
    "df_train.loc[df_train['kitch_sq'] > 250, 'kitch_sq'] = np.median(df_train['kitch_sq'].dropna())\n",
    "df_train.loc[df_train['num_room'] > 6, 'num_room'] = np.median(df_train['num_room'].dropna())\n",
    "df_train.loc[df_train['floor'] > 50, 'floor'] = np.median(df_train['floor'].dropna())\n",
    "df_train.loc[df_train['max_floor'] > 60, 'max_floor'] = np.median(df_train['max_floor'].dropna())\n",
    "df_train.loc[df_train.full_sq == 0, 'full_sq'] = 50\n",
    "df_train = df_train[df_train.price_doc/df_train.full_sq <= 600000]\n",
    "df_train = df_train[df_train.price_doc/df_train.full_sq >= 10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add month and day of week\n",
    "df_train['month'] = df_train.timestamp.dt.month\n",
    "df_train['dow'] = df_train.timestamp.dt.dayofweek\n",
    "\n",
    "df_test['month'] = df_test.timestamp.dt.month\n",
    "df_test['dow'] = df_test.timestamp.dt.dayofweek\n",
    "\n",
    "# Other feature engineering\n",
    "df_train['rel_floor'] = df_train['floor'] / df_train['max_floor'].astype(float)\n",
    "df_train['rel_kitch_sq'] = df_train['kitch_sq'] / df_train['full_sq'].astype(float)\n",
    "df_test['rel_floor'] = df_test['floor'] / df_test['max_floor'].astype(float)\n",
    "df_test['rel_kitch_sq'] = df_test['kitch_sq'] / df_test['full_sq'].astype(float)\n",
    "\n",
    "df_train.apartment_name=df_train.sub_area + df_train['metro_km_avto'].astype(str)\n",
    "df_test.apartment_name=df_test.sub_area + df_train['metro_km_avto'].astype(str)\n",
    "\n",
    "df_train['room_size'] = df_train['life_sq'] / df_train['num_room'].astype(float)\n",
    "df_test['room_size'] = df_test['life_sq'] / df_test['num_room'].astype(float)\n",
    "\n",
    "# Average price corresponding to sub_area \n",
    "id_features = ['ID_metro',\n",
    "    'ID_railroad_station_walk', \\\n",
    "    'ID_big_road1', \\\n",
    "    'ID_big_road2', \\\n",
    "    'ID_railroad_terminal', \\\n",
    "    'ID_bus_terminal']\n",
    "\n",
    "df_test['avg_price_sub_area'] = 0.0\n",
    "df_train['avg_price_sub_area'] = 0.0\n",
    "for subarea in df_train['sub_area'].unique():\n",
    "    avg = df_train[df_train['sub_area'] == subarea]['price_doc'].mean()\n",
    "    df_train.loc[df_train['sub_area'] == subarea, 'avg_price_sub_area'] = avg\n",
    "    df_test.loc[df_test['sub_area'] == subarea, 'avg_price_sub_area'] = avg\n",
    "del df_train['sub_area']\n",
    "del df_test['sub_area']\n",
    "\n",
    "for id_f in id_features:\n",
    "    df_train['avg_price_' + id_f] = 0.0\n",
    "    for val in df_train[id_f].unique():\n",
    "        avg = df_train[df_train[id_f] == val]['price_doc'].mean()\n",
    "        df_train.loc[df_train[id_f] == val, 'avg_price_' + id_f] = avg\n",
    "    del df_train[id_f]\n",
    "    \n",
    "cols = list(df_train.columns.values)\n",
    "cols.pop(cols.index('price_doc'))\n",
    "df_train = df_train[cols + ['price_doc']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Missing Data Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute numeric data with mean and categorical data with mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric\n",
    "for col in df_train._get_numeric_data().columns[df_train._get_numeric_data().isnull().any()]:\n",
    "    df_train[col].fillna(df_train[col].mean(), inplace=True)\n",
    "for col in df_test._get_numeric_data().columns[df_test._get_numeric_data().isnull().any()]:\n",
    "    df_test[col].fillna(df_test[col].mean(), inplace=True)\n",
    "\n",
    "# categorical \n",
    "for col in df_train.columns[df_train.isnull().any()].tolist():\n",
    "    df_train[col].fillna(df_train[col].value_counts().index[0], inplace=True)\n",
    "for col in df_test.columns[df_test.isnull().any()].tolist():\n",
    "    df_test[col].fillna(df_train[col].value_counts().index[0], inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
