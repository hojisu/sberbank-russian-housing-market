{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 191108\n",
    "- outlier drop 해보기\n",
    "- Missing value ; nan 50% 이상이면 drop, numeric -> median, cat -> mode로 해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing & Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Feature/Data Transformation\n",
    "- Outlier\n",
    "- New Features\n",
    "\n",
    "## 2.Missing Data Imputation\n",
    "- Numeric columns: median\n",
    "- Categorical columns: mode\n",
    "\n",
    "## 3.Dimensionality Reduction\n",
    "- Features with Bad or Constant Data\n",
    "- Multicollinearity and Variance Inflation Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "import datetime\n",
    "import scipy as sp\n",
    "import statsmodels.stats.api as sms\n",
    "import statsmodels.api as sm\n",
    "from patsy import dmatrix\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import utils.preprocessing as pp \n",
    "import utils.correlation as cr\n",
    "import utils.statsmodel_helper as st\n",
    "\n",
    "df_macro = pd.read_csv('../code/data/macro.csv', parse_dates=['timestamp'])\n",
    "df_train = pd.read_csv('../code/data/train.csv', index_col=0, parse_dates=['timestamp'])\n",
    "df_test = pd.read_csv('../code/data/test.csv', index_col=0, parse_dates=['timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Feature/Data Transformation\n",
    "- Outlier\n",
    "- New Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop data with extremely big price #\n",
    "df_train = df_train.drop([2121])\n",
    "# Drop outliers with proper value #\n",
    "df_train.drop(df_train.index[df_train['state'] == 33], inplace = True)\n",
    "df_train.drop(df_train.index[df_train['life_sq'] > 100], inplace = True)\n",
    "df_train.drop(df_train.index[df_train['kitch_sq'] > 250], inplace = True)\n",
    "df_train.drop(df_train.index[df_train['num_room'] > 6], inplace = True)\n",
    "df_train.drop(df_train.index[df_train['build_year'] > 2017], inplace = True)\n",
    "df_train.drop(df_train.index[df_train['build_year'] < 1800], inplace = True)\n",
    "df_train.drop(df_train.index[df_train['floor'] > 50], inplace = True)\n",
    "df_train.drop(df_train.index[df_train['max_floor'] > 60], inplace = True)\n",
    "df_train.drop(df_train.index[df_train['full_sq']  == 0], inplace = True)\n",
    "df_train.drop(df_train.index[df_train['full_sq']  == 0], inplace = True)\n",
    "\n",
    "# df_train = df_train[df_train.price_doc/df_train.full_sq <= 600000]\n",
    "# df_train = df_train[df_train.price_doc/df_train.full_sq >= 10000]\n",
    "\n",
    "df_test.drop(df_test.index[df_test['life_sq'] > 100], inplace = True)\n",
    "df_test.drop(df_test.index[df_test['kitch_sq'] > 250], inplace = True)\n",
    "df_test.drop(df_test.index[df_test['num_room'] > 6], inplace = True)\n",
    "df_test.drop(df_test.index[df_test['build_year'] > 2017], inplace = True)\n",
    "df_test.drop(df_test.index[df_test['build_year'] < 1800], inplace = True)\n",
    "df_test.drop(df_test.index[df_test['floor'] > 50], inplace = True)\n",
    "df_test.drop(df_test.index[df_test['max_floor'] > 60], inplace = True)\n",
    "df_test.drop(df_test.index[df_test['full_sq']  == 0], inplace = True)\n",
    "df_test.drop(df_test.index[df_test['full_sq']  == 0], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add month and day of week #\n",
    "df_train['month'] = df_train.timestamp.dt.month\n",
    "df_train['dow'] = df_train.timestamp.dt.dayofweek\n",
    "\n",
    "df_test['month'] = df_test.timestamp.dt.month\n",
    "df_test['dow'] = df_test.timestamp.dt.dayofweek\n",
    "\n",
    "# Create new features that might help #\n",
    "df_train['rel_floor'] = df_train['floor'] / df_train['max_floor'].astype(float)\n",
    "df_train['rel_kitch_sq'] = df_train['kitch_sq'] / df_train['full_sq'].astype(float)\n",
    "\n",
    "df_test['rel_floor'] = df_test['floor'] / df_test['max_floor'].astype(float)\n",
    "df_test['rel_kitch_sq'] = df_test['kitch_sq'] / df_test['full_sq'].astype(float)\n",
    "\n",
    "df_train.apartment_name=df_train.sub_area + df_train['metro_km_avto'].astype(str)\n",
    "df_test.apartment_name=df_test.sub_area + df_train['metro_km_avto'].astype(str)\n",
    "\n",
    "df_train['room_size'] = df_train['life_sq'] / df_train['num_room'].astype(float)\n",
    "df_test['room_size'] = df_test['life_sq'] / df_test['num_room'].astype(float)\n",
    "\n",
    "# Average price corresponding to sub_area and ID_* #\n",
    "# id_features = ['ID_metro',\n",
    "#     'ID_railroad_station_walk', \\\n",
    "#     'ID_big_road1', \\\n",
    "#     'ID_big_road2', \\\n",
    "#     'ID_railroad_terminal', \\\n",
    "#     'ID_bus_terminal']\n",
    "\n",
    "# for id_f in id_features:\n",
    "#     df_test['avg_price_' + id_f] = 0.0\n",
    "#     for val in df_test[id_f].unique():\n",
    "#         if val == 171 and id_f == 'ID_metro':\n",
    "#             df_test.loc[df_test.ID_metro == 171, 'avg_price_ID_metro'] = df_train[df_train.ID_metro == 170]['price_doc'].mean()\n",
    "#             continue\n",
    "#         if val == 132 and id_f == 'ID_railroad_station_walk':\n",
    "#             df_test.loc[df_test.ID_railroad_station_walk == 132, 'avg_price_ID_railroad_station_walk'] = df_train[df_train.ID_railroad_station_walk == 131]['price_doc'].mean()\n",
    "#             continue\n",
    "#         if val == 121 and id_f == 'ID_railroad_station_walk':\n",
    "#             df_test.loc[df_test.ID_railroad_station_walk == 122, 'avg_price_ID_railroad_station_walk'] = df_train[df_train.ID_railroad_station_walk == 131]['price_doc'].mean()\n",
    "#             continue\n",
    "#         avg = df_train[df_train[id_f] == val]['price_doc'].mean()\n",
    "#         df_test.loc[df_test[id_f] == val, 'avg_price_' + id_f] = avg\n",
    "#     del df_test[id_f]\n",
    "    \n",
    "# for id_f in id_features:\n",
    "#     df_train['avg_price_' + id_f] = 0.0\n",
    "#     for val in df_train[id_f].unique():\n",
    "#         avg = df_train[df_train[id_f] == val]['price_doc'].mean()\n",
    "#         df_train.loc[df_train[id_f] == val, 'avg_price_' + id_f] = avg\n",
    "#     del df_train[id_f]\n",
    "    \n",
    "# cols = list(df_train.columns.values)\n",
    "# cols.pop(cols.index('price_doc'))\n",
    "# df_train = df_train[cols + ['price_doc']]\n",
    "\n",
    "\n",
    "df_test['avg_price_sub_area'] = 0.0\n",
    "df_train['avg_price_sub_area'] = 0.0\n",
    "for subarea in df_train['sub_area'].unique():\n",
    "    avg = df_train[df_train['sub_area'] == subarea]['price_doc'].mean()\n",
    "    df_train.loc[df_train['sub_area'] == subarea, 'avg_price_sub_area'] = avg\n",
    "    df_test.loc[df_test['sub_area'] == subarea, 'avg_price_sub_area'] = avg\n",
    "del df_train['sub_area']\n",
    "del df_test['sub_area']\n",
    "\n",
    "\n",
    "# Add the Macro Feature #\n",
    "usdrub_pairs = dict(zip(list(df_macro['timestamp']), list(df_macro['usdrub'])))\n",
    "\n",
    "df_train['timestamp'].replace(usdrub_pairs,inplace=True)\n",
    "df_test['timestamp'].replace(usdrub_pairs,inplace=True)\n",
    "\n",
    "df_train.rename(columns={'timestamp' : 'usdrub'}, inplace=True)\n",
    "df_test.rename(columns={'timestamp' : 'usdrub'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Missing Data Imputation\n",
    "- Numeric columns: median\n",
    "- Categorical columns: mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df_train._get_numeric_data()[df_train._get_numeric_data() < 0] = 0\n",
    "df_test._get_numeric_data()[df_test._get_numeric_data() < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric #\n",
    "for col in df_train._get_numeric_data().columns[df_train._get_numeric_data().columns.isnull().any()].tolist():\n",
    "    df_train[col].fillna(df_train[col].median(), inplace=True)\n",
    "for col in df_test._get_numeric_data().columns[df_test._get_numeric_data().columns.isnull().any()].tolist():\n",
    "    df_test[col].fillna(df_train[col].median(), inplace=True)\n",
    "\n",
    "# categorical #\n",
    "for col in list(set(df_train.columns) - set(df_train._get_numeric_data().columns)):\n",
    "    df_train[col].fillna(df_train[col].value_counts().index[0], inplace=True)\n",
    "for col in list(set(df_test.columns) - set(df_test._get_numeric_data().columns)):\n",
    "    df_test[col].fillna(df_test[col].value_counts().index[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dimensionality Reduction\n",
    "### Features with Bad or Constant Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features with high correlation with other #\n",
    "features_to_remove = [\n",
    "    'children_preschool', 'children_school', 'male_f', \\\n",
    "    'female_f', 'young_male', 'young_female', 'work_male', \\\n",
    "    'work_female', 'ekder_male', 'ekder_female',\\\n",
    "    '0_6_all', '0_6_male', '0_6_female',\\\n",
    "    '7_14_all', '7_14_male', '7_14_female', '0_17_male', '0_17_female',\\\n",
    "    '16_29_male', '16_29_female', '0_13_all', '0_13_male', '0_13_female',\\\n",
    "    'metro_km_walk', 'railroad_station_walk_km',\\\n",
    "    'railroad_station_avto_km', 'public_transport_station_km' \\\n",
    "]\n",
    "for f in features_to_remove:\n",
    "    del df_train[f]\n",
    "    del df_test[f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant features #\n",
    "consts = [col for col in df_train.columns if len(df_train[col].value_counts().index) == 1]\n",
    "for const in consts:\n",
    "    del df_train[const]\n",
    "    del df_test[const]\n",
    "    \n",
    "consts = [col for col in df_macro.columns if len(df_macro[col].value_counts().index) == 1]\n",
    "for const in consts:\n",
    "    del df_macro[const]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multicollinearity and Variance Inflation Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low correlation with price #\n",
    "corr_limit = 0.1\n",
    "for column in df_train._get_numeric_data().columns.drop('price_doc').values:\n",
    "    if abs(df_train[column].corr(df_train['price_doc'])) < corr_limit:\n",
    "        df_train = df_train.drop(column, axis=1)\n",
    "        if column in df_test.columns.values:\n",
    "            df_test = df_test.drop(column, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate VIF #\n",
    "df_train[df_train==np.inf]=np.nan\n",
    "df_train.fillna(df_train.mean(), inplace=True)\n",
    "categorial_ivs = set(df_train.columns) - set(df_train._get_numeric_data().columns)\n",
    "numeric_ivs = df_train._get_numeric_data().columns.drop('price_doc')\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(\n",
    "    df_train[numeric_ivs].values, i) for i in range(df_train[numeric_ivs].shape[1])]\n",
    "vif[\"features\"] = df_train[numeric_ivs].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['raion_popul',\n",
       " 'preschool_education_centers_raion',\n",
       " 'school_education_centers_raion',\n",
       " 'young_all',\n",
       " 'work_all',\n",
       " 'ekder_all',\n",
       " '0_17_all',\n",
       " 'metro_min_avto',\n",
       " 'metro_km_avto',\n",
       " 'metro_min_walk',\n",
       " 'school_km',\n",
       " 'park_km',\n",
       " 'railroad_station_walk_min',\n",
       " 'railroad_station_avto_min',\n",
       " 'ttk_km',\n",
       " 'sadovoe_km',\n",
       " 'bulvar_ring_km',\n",
       " 'kremlin_km',\n",
       " 'zd_vokzaly_avto_km',\n",
       " 'bus_terminal_avto_km',\n",
       " 'oil_chemistry_km',\n",
       " 'nuclear_reactor_km',\n",
       " 'radiation_km',\n",
       " 'power_transmission_line_km',\n",
       " 'thermal_power_plant_km',\n",
       " 'ts_km',\n",
       " 'stadium_km',\n",
       " 'basketball_km',\n",
       " 'detention_facility_km',\n",
       " 'university_km',\n",
       " 'workplaces_km',\n",
       " 'preschool_km',\n",
       " 'mosque_km',\n",
       " 'theater_km',\n",
       " 'museum_km',\n",
       " 'exhibition_km',\n",
       " 'cafe_count_500',\n",
       " 'office_count_1000',\n",
       " 'cafe_count_1000_price_1000',\n",
       " 'cafe_count_1000_price_1500',\n",
       " 'office_count_1500',\n",
       " 'cafe_count_1500',\n",
       " 'cafe_sum_1500_min_price_avg',\n",
       " 'cafe_sum_1500_max_price_avg',\n",
       " 'cafe_avg_price_1500',\n",
       " 'cafe_count_1500_na_price',\n",
       " 'cafe_count_1500_price_1000',\n",
       " 'cafe_count_1500_price_1500',\n",
       " 'cafe_count_1500_price_2500',\n",
       " 'office_count_2000',\n",
       " 'cafe_count_2000',\n",
       " 'cafe_count_2000_na_price',\n",
       " 'cafe_count_2000_price_500',\n",
       " 'cafe_count_2000_price_1000',\n",
       " 'cafe_count_2000_price_1500',\n",
       " 'cafe_count_2000_price_2500',\n",
       " 'cafe_count_2000_price_high',\n",
       " 'sport_count_2000',\n",
       " 'green_part_3000',\n",
       " 'office_count_3000',\n",
       " 'office_sqm_3000',\n",
       " 'trc_count_3000',\n",
       " 'cafe_count_3000',\n",
       " 'cafe_count_3000_na_price',\n",
       " 'cafe_count_3000_price_500',\n",
       " 'cafe_count_3000_price_1000',\n",
       " 'cafe_count_3000_price_1500',\n",
       " 'cafe_count_3000_price_2500',\n",
       " 'cafe_count_3000_price_4000',\n",
       " 'cafe_count_3000_price_high',\n",
       " 'big_church_count_3000',\n",
       " 'church_count_3000',\n",
       " 'leisure_count_3000',\n",
       " 'sport_count_3000',\n",
       " 'green_part_5000',\n",
       " 'office_count_5000',\n",
       " 'office_sqm_5000',\n",
       " 'trc_count_5000',\n",
       " 'cafe_count_5000',\n",
       " 'cafe_count_5000_na_price',\n",
       " 'cafe_count_5000_price_500',\n",
       " 'cafe_count_5000_price_1000',\n",
       " 'cafe_count_5000_price_1500',\n",
       " 'cafe_count_5000_price_2500',\n",
       " 'cafe_count_5000_price_4000',\n",
       " 'cafe_count_5000_price_high',\n",
       " 'big_church_count_5000',\n",
       " 'church_count_5000',\n",
       " 'leisure_count_5000',\n",
       " 'sport_count_5000',\n",
       " 'avg_price_sub_area']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vif.loc[vif['VIF Factor'] > 50].features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features with VIF greater than 30\n",
    "features_to_remove = [\n",
    "'raion_popul',\n",
    " 'preschool_education_centers_raion',\n",
    " 'school_education_centers_raion',\n",
    " 'young_all',\n",
    " 'work_all',\n",
    " 'ekder_all',\n",
    " '0_17_all',\n",
    " 'metro_min_avto',\n",
    " 'metro_km_avto',\n",
    " 'metro_min_walk',\n",
    " 'school_km',\n",
    " 'park_km',\n",
    " 'railroad_station_walk_min',\n",
    " 'railroad_station_avto_min',\n",
    " 'ttk_km',\n",
    " 'sadovoe_km',\n",
    " 'bulvar_ring_km',\n",
    " 'kremlin_km',\n",
    " 'zd_vokzaly_avto_km',\n",
    " 'bus_terminal_avto_km',\n",
    " 'oil_chemistry_km',\n",
    " 'nuclear_reactor_km',\n",
    " 'radiation_km',\n",
    " 'power_transmission_line_km',\n",
    " 'thermal_power_plant_km',\n",
    " 'ts_km',\n",
    " 'stadium_km',\n",
    " 'basketball_km',\n",
    " 'detention_facility_km',\n",
    " 'university_km',\n",
    " 'workplaces_km',\n",
    " 'preschool_km',\n",
    " 'mosque_km',\n",
    " 'theater_km',\n",
    " 'museum_km',\n",
    " 'exhibition_km',\n",
    " 'cafe_count_500',\n",
    " 'office_count_1000',\n",
    " 'cafe_count_1000_price_1000',\n",
    " 'cafe_count_1000_price_1500',\n",
    " 'office_count_1500',\n",
    " 'cafe_count_1500',\n",
    " 'cafe_sum_1500_min_price_avg',\n",
    " 'cafe_sum_1500_max_price_avg',\n",
    " 'cafe_avg_price_1500',\n",
    " 'cafe_count_1500_na_price',\n",
    " 'cafe_count_1500_price_1000',\n",
    " 'cafe_count_1500_price_1500',\n",
    " 'cafe_count_1500_price_2500',\n",
    " 'office_count_2000',\n",
    " 'cafe_count_2000',\n",
    " 'cafe_count_2000_na_price',\n",
    " 'cafe_count_2000_price_500',\n",
    " 'cafe_count_2000_price_1000',\n",
    " 'cafe_count_2000_price_1500',\n",
    " 'cafe_count_2000_price_2500',\n",
    " 'cafe_count_2000_price_high',\n",
    " 'sport_count_2000',\n",
    " 'green_part_3000',\n",
    " 'office_count_3000',\n",
    " 'office_sqm_3000',\n",
    " 'trc_count_3000',\n",
    " 'cafe_count_3000',\n",
    " 'cafe_count_3000_na_price',\n",
    " 'cafe_count_3000_price_500',\n",
    " 'cafe_count_3000_price_1000',\n",
    " 'cafe_count_3000_price_1500',\n",
    " 'cafe_count_3000_price_2500',\n",
    " 'cafe_count_3000_price_4000',\n",
    " 'cafe_count_3000_price_high',\n",
    " 'big_church_count_3000',\n",
    " 'church_count_3000',\n",
    " 'leisure_count_3000',\n",
    " 'sport_count_3000',\n",
    " 'green_part_5000',\n",
    " 'office_count_5000',\n",
    " 'office_sqm_5000',\n",
    " 'trc_count_5000',\n",
    " 'cafe_count_5000',\n",
    " 'cafe_count_5000_na_price',\n",
    " 'cafe_count_5000_price_500',\n",
    " 'cafe_count_5000_price_1000',\n",
    " 'cafe_count_5000_price_1500',\n",
    " 'cafe_count_5000_price_2500',\n",
    " 'cafe_count_5000_price_4000',\n",
    " 'cafe_count_5000_price_high',\n",
    " 'big_church_count_5000',\n",
    " 'church_count_5000',\n",
    " 'leisure_count_5000',\n",
    " 'sport_count_5000',\n",
    " 'avg_price_ID_metro',\n",
    " 'avg_price_ID_railroad_station_walk',\n",
    " 'avg_price_ID_big_road1',\n",
    " 'avg_price_ID_big_road2',\n",
    " 'avg_price_ID_railroad_terminal',\n",
    " 'avg_price_ID_bus_terminal',\n",
    " 'avg_price_sub_area'\n",
    "]\n",
    "\n",
    "for f in features_to_remove:\n",
    "    if f in df_train:\n",
    "        del df_train[f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(df_train.columns.values)\n",
    "cols.pop(cols.index('price_doc'))\n",
    "df_train = df_train[cols + ['price_doc']]\n",
    "df_train.to_csv('./data/train_macro7.csv', header=True, index=True)\n",
    "df_test.to_csv('./data/test_macro7.csv', header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
