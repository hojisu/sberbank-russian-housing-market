{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling with Scikit-Learn Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing\n",
    "- Lable-Encoding\n",
    "- Log nomalization\n",
    "- Standard scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Regressors : Scikit-Learn\n",
    "- DecisionTree Regressor\n",
    "- RandomForest Regressor\n",
    "- Support Vector Regressor\n",
    "- XGB Regressor\n",
    "- Cross-validation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Score by Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname('github'))))\n",
    "import utils.statsmodel_helper as sh\n",
    "import utils.feature_selection as fs\n",
    "import utils.preprocessing as pp\n",
    "import utils.error_calculator as ec\n",
    "import utils.helpermodeling as hm\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "from sklearn.model_selection import KFold, ParameterGrid, cross_val_score, cross_val_predict, GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, make_scorer\n",
    "from sklearn.metrics import r2_score, explained_variance_score\n",
    "\n",
    "# model import\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(y_test, pred, measured, preds):\n",
    "    print('\\n')\n",
    "    print(\"Train Test Split\")\n",
    "    print('RMSE:', np.sqrt(mean_squared_error(y_test, pred)))\n",
    "\n",
    "    print('\\n')\n",
    "    print(\"Cross Validation\")\n",
    "    print('RMSE:', np.sqrt(mean_squared_error(measured, preds)))\n",
    "\n",
    "    fig  = plt.figure(figsize=(8, 4), dpi=100)\n",
    "    axes1 = fig.add_subplot(121)\n",
    "    axes1.scatter(y_test, pred, c='red', s=5)\n",
    "    axes1.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "    axes1.set_title(\"Train Test Split\")\n",
    "    axes1.set_xlabel('Measured')\n",
    "    axes1.set_ylabel('Predicted')\n",
    "    axes2 = fig.add_subplot(122)\n",
    "    axes2.scatter(measured, preds, c='red', s=5)\n",
    "    axes2.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "    axes2.set_title(\"Cross Validation\")\n",
    "    axes2.set_xlabel('Measured')\n",
    "    axes2.set_ylabel('Predicted')\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    fig  = plt.figure(figsize=(8, 4), dpi=100);\n",
    "    axes1 = fig.add_subplot(121); \n",
    "    axes1.scatter(y_test, y_test-pred, c='red', s=2)\n",
    "    axes1.set_title(\"Train Test Split\")\n",
    "    axes1.set_xlabel('Measured')\n",
    "    axes1.set_ylabel('Residual')\n",
    "    axes2 = fig.add_subplot(122); \n",
    "    axes2.scatter(measured, measured-preds, c='red', s=2)\n",
    "    axes2.set_title(\"Cross Validation\")\n",
    "    axes2.set_xlabel('Measured')\n",
    "    axes2.set_ylabel('Residual')\n",
    "    fig.tight_layout();\n",
    "    \n",
    "    fig  = plt.figure(figsize=(8, 4), dpi=100)\n",
    "    axes1 = fig.add_subplot(121)\n",
    "    axes2 = fig.add_subplot(122)\n",
    "    sns.distplot((y_test-pred), bins=50, ax=axes1, axlabel='Error Deviation', kde_kws={\"color\": \"k\", \"lw\": 1.5, \"gridsize\":1000}, hist_kws={\"linewidth\": 3, \"alpha\": 0.6, \"color\": \"red\"})\n",
    "    sns.distplot((measured-preds), bins=50, ax=axes2, axlabel='Error Deviation', kde_kws={\"color\": \"k\", \"lw\": 1.5, \"gridsize\":1000}, hist_kws={\"linewidth\": 3, \"alpha\": 0.6, \"color\": \"red\"})\n",
    "    axes1.set_title(\"Train Test Split\")\n",
    "    axes2.set_title(\"Cross Validation\")\n",
    "    axes1.set_xlim(-3, 3)\n",
    "    axes2.set_xlim(-3, 3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../input/train.csv', index_col=0, parse_dates=['timestamp'])\n",
    "# df_train_augmented = pd.read_csv('../input/train_macro_with_outliers.csv', index_col=0, parse_dates=['timestamp'])\n",
    "df_test = pd.read_csv('../input/test.csv', index_col=0, parse_dates=['timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorial_ivs = list(set(df_train.columns.drop('timestamp')) - set(df_train._get_numeric_data().columns)) \n",
    "numeric_features = list(df_train.columns.drop(categorial_ivs + ['price_doc']  + ['timestamp']).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorial_ivs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[numeric_features].tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lable-Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in categorial_ivs:\n",
    "    df_train[f].fillna(df_train[f].value_counts().index[0], inplace=True)\n",
    "    df_test[f].fillna(df_test[f].value_counts().index[0], inplace=True)\n",
    "#     df_train_augmented[f].fillna(df_train_augmented[f].value_counts().index[0], inplace=True)\n",
    "    \n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(df_train[f].values)\n",
    "    df_train[f] = lbl.transform(df_train[f].values)\n",
    "    df_test[f] = lbl.transform(df_test[f].values)\n",
    "#     df_train_augmented[f] = LabelEncoder().fit_transform(df_train_augmented[f].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log nomalizaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log Normalization of Numeric Features\n",
    "for column in numeric_features + ['price_doc']:\n",
    "    if stats.skew(df_train[column].values) > 1:\n",
    "        df_train[column] = np.log(df_train[column] + 1)  \n",
    "#         df_train_augmented[column] = np.log(df_train_augmented[column] + 1)\n",
    "        if column in df_test.columns.values:\n",
    "            df_test[column]  = np.log(df_test[column] + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균 0 표준편차 1이 되도록 스케일링\n",
    "train_scaler = StandardScaler()\n",
    "train_scaler.fit(df_train[numeric_features])\n",
    "\n",
    "scaled_numeric_train_X = train_scaler.transform(df_train[numeric_features])\n",
    "df_scaled_numeric_train_X = pd.DataFrame(scaled_numeric_train_X, index=df_train.index, columns=numeric_features)\n",
    "df_train = pd.concat([df_scaled_numeric_train_X, df_train[categorial_ivs], df_train['price_doc']], axis=1)\n",
    "\n",
    "scaled_numeric_test_X = train_scaler.transform(df_test[numeric_features])\n",
    "df_scaled_numeric_test_X = pd.DataFrame(scaled_numeric_test_X, index=df_test.index, columns=numeric_features)\n",
    "df_test = pd.concat([df_scaled_numeric_test_X, df_test[categorial_ivs]], axis=1)\n",
    "\n",
    "# train_scaler = StandardScaler()\n",
    "# train_scaler.fit(df_train_augmented[numeric_features])\n",
    "\n",
    "# scaled_numeric_train_X = train_scaler.transform(df_train_augmented[numeric_features])\n",
    "# df_scaled_numeric_train_X = pd.DataFrame(scaled_numeric_train_X, index=df_train_augmented.index, columns=numeric_features)\n",
    "# df_train_augmented = pd.concat([df_scaled_numeric_train_X, df_train_augmented[cate_features], df_train_augmented['price_doc']],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Regressors : Scikit-Learn\n",
    "- Decision Tree Regressor\n",
    "- RandomForest Regressor\n",
    "- Support Vector Regressor\n",
    "- XGB(Extreme Gradient Boosting) Regressor\n",
    "- Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_train[numeric_features+categorial_ivs], df_train['price_doc'], test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr = DecisionTreeRegressor()\n",
    "y_train_dtr, y_test_dtr = hm.regression(dtr, X_train, X_test, y_train)\n",
    "hm.scores('Decision Tree Regressor', y_train, y_test, y_train_dtr, y_test_dtr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor()\n",
    "y_train_rfr, y_test_rfr = hm.regression(rfr, X_train, X_test, y_train)\n",
    "hm.scores('RandomForest Regressor', y_train, y_test, y_train_rfr, y_test_rfr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr = SVR(gamma='scale', C=1.0, epsilon=0.2)\n",
    "y_train_svr, y_test_svr = hm.regression(svr, X_train, X_test, y_train)\n",
    "hm.scores('Support Vector Regressor', y_train, y_test, y_train_svr, y_test_svr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{\n",
    "    'max_depth': [10],\n",
    "    'learning_rate' : [0.1],\n",
    "    'n_estimators' : [200], \n",
    "    'colsample_bytree': [0.5]\n",
    "}]\n",
    "\n",
    "xgr = xgb.XGBRegressor()\n",
    "grid_xgr = GridSearchCV(xgr, param_grid, cv=cv, n_jobs=4, scoring='neg_mean_squared_log_error')\n",
    "grid_xgr.fit(X_train, y_train)\n",
    "print(grid_xgr.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgr = xgb.XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=0.5, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=10, min_child_weight=1, missing=None, n_estimators=200,\n",
    "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_xgr, y_test_xgr = hm.regression(xgr, X_train, X_test, y_train)\n",
    "hm.scores('XGB Regressor', y_train, y_test, y_train_xgr, y_test_xgr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = grid_xgr.best_estimator_.predict(X_test)\n",
    "sns.distplot(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = cross_val_predict(grid_xgr.best_estimator_, \n",
    "                                df_train[numeric_features+categorial_ivs], \n",
    "                                df_train['price_doc'], \n",
    "                                cv=cv)\n",
    "\n",
    "show_results(y_test, \n",
    "             prediction, \n",
    "             df_train['price_doc'], \n",
    "             predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = grid_xgr.best_estimator_.predict(df_test)\n",
    "sns.distplot(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.exp(predictions)\n",
    "df_pred= pd.DataFrame({'price_doc' : y_pred})\n",
    "df_test1 = pd.read_csv('../input/test.csv',  parse_dates=['timestamp'])\n",
    "df1 = pd.concat([df_test1, df_pred], axis=1)\n",
    "df2 = df1[['id', 'price_doc']]\n",
    "df2.set_index('id', inplace=True)\n",
    "# df3 = pd.read_csv('../submissions/stats_models_2019_12_13_19_46_01.csv', index_col=0)\n",
    "df2.to_csv('../submissions/stats_models_{}.csv'.format(datetime.datetime.now().strftime('%Y_%m_%d_%H_%M_%S')), header=True, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.36725"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 50))\n",
    "xgb.plot_importance(grid_xgr.best_estimator_, height=0.5, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr_r2 = cross_val_score(dtr, X_train, y_train, scoring='r2', cv=cv)\n",
    "rfr_r2 = cross_val_score(rfr, X_train, y_train, scoring='r2', cv=cv)\n",
    "svr_r2 = cross_val_score(svr, X_train, y_train, scoring='r2', cv=cv)\n",
    "xgr_r2 = cross_val_score(xgr, X_train, y_train, scoring='r2', cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(actual_values, predicted_values, convertExp=True):\n",
    "    \"\"\"\n",
    "    - root mean squared log error는 error를 로그화값으로 변환하고, 제곱하고, 평균을 내고, 루트를 씌웁니다.\n",
    "    - skewness를 해결하기 위해 np.log1p를 했기 때문에, 값을 예측할 때 이를 다시 변환해서 처리해주는 것이 필요합니다. \n",
    "    \"\"\"\n",
    "    if convertExp==True:\n",
    "        predicted_values = np.exp(predicted_values),\n",
    "        actual_values = np.array(np.exp(actual_values))\n",
    "        \n",
    "    log_predicted_values = np.log(np.array(predicted_values)+1)\n",
    "    log_actual_values = np.log(np.array(actual_values)+1)\n",
    "\n",
    "    # 위에서 계산한 예측값에서 실제값을 빼주고 제곱을 해준다.\n",
    "    difference = np.square(log_predicted_values - log_actual_values)\n",
    "    return np.sqrt(difference.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr_train_rmsle = - cross_val_score(dtr, X_train, y_train, scoring=make_scorer(rmsle, greater_is_better=False), cv=cv)\n",
    "rfr_train_rmsle = - cross_val_score(rfr, X_train, y_train, scoring=make_scorer(rmsle, greater_is_better=False), cv=cv)\n",
    "svr_train_rmsle = - cross_val_score(svr, X_train, y_train, scoring=make_scorer(rmsle, greater_is_better=False), cv=cv)\n",
    "xgr_train_rmsle = - cross_val_score(xgr, X_train, y_train, scoring=make_scorer(rmsle, greater_is_better=False), cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr_test_rmsle = - cross_val_score(dtr, X_test, y_test, scoring=make_scorer(rmsle, greater_is_better=False), cv=cv)\n",
    "rfr_test_rmsle = - cross_val_score(rfr, X_test, y_test, scoring=make_scorer(rmsle, greater_is_better=False), cv=cv)\n",
    "svr_test_rmsle = - cross_val_score(svr, X_test, y_test, scoring=make_scorer(rmsle, greater_is_better=False), cv=cv)\n",
    "xgr_test_rmsle = - cross_val_score(xgr, X_test, y_test, scoring=make_scorer(rmsle, greater_is_better=False), cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score = pd.DataFrame({'DecisionTreeRegressor' : dtr_r2, 'RandomForestRegressor' : rfr_r2, 'SupportVectorRegressor' : svr_r2, 'XGBRegressor' : xgr_r2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsle_train = pd.DataFrame({'DecisionTreeRegressor' : dtr_train_rmsle, 'RandomForestRegressor' : rfr_train_rmsle, 'SupportVectorRegressor' : svr_train_rmsle, 'XGBRegressor' : xgr_train_rmsle})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsle_test = pd.DataFrame({'DecisionTreeRegressor' : dtr_test_rmsle, 'RandomForestRegressor' : rfr_test_rmsle, 'SupportVectorRegressor' : svr_test_rmsle, 'XGBRegressor' : xgr_test_rmsle})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## boxplot\n",
    "plt.figure(figsize=(12, 7))\n",
    "r2_score.boxplot(column= ['DecisionTreeRegressor', 'RandomForestRegressor', 'SupportVectorRegressor', 'XGBRegressor']) \n",
    "plt.xticks(size = 10, rotation=45)\n",
    "plt.yticks(size = 10)\n",
    "plt.title('r2 by Model')\n",
    "plt.ylabel(\"r2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## boxplot\n",
    "plt.figure(figsize=(12, 7))\n",
    "rmsle_train.boxplot(column= ['DecisionTreeRegressor', 'RandomForestRegressor', 'SupportVectorRegressor', 'XGBRegressor']) \n",
    "plt.xticks(size = 10, rotation=45)\n",
    "plt.yticks(size = 10)\n",
    "plt.title('RMSLE_train by Model')\n",
    "plt.ylabel(\"RMSLE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## boxplot\n",
    "plt.figure(figsize=(12, 7))\n",
    "rmsle_test.boxplot(column= ['DecisionTreeRegressor', 'RandomForestRegressor', 'SupportVectorRegressor', 'XGBRegressor']) \n",
    "plt.xticks(size = 10, rotation=45)\n",
    "plt.yticks(size = 10)\n",
    "plt.title('RMSLE_test by Model')\n",
    "plt.ylabel(\"RMSLE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
